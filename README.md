# ğŸ§  LLM Local sur Mini PC NUC

![Banner](https://raw.githubusercontent.com/creach-t/mini-nuc-llm/main/images/banner.jpg)

> *"L'intelligence artificielle Ã  portÃ©e de main, sans connexion internet, sans abonnement, dans votre salon."*

## ğŸ“‹ Vue d'ensemble

Ce projet vous guide dans l'installation et l'exÃ©cution de grands modÃ¨les de langage (LLM) sur un Mini PC NUC avec processeur Intel i5. Contrairement aux solutions cloud, cette approche vous permet de :

- **Garder vos donnÃ©es privÃ©es** - Tout reste sur votre machine
- **Fonctionner hors ligne** - Pas besoin d'internet pour gÃ©nÃ©rer du texte
- **Ã‰conomiser** - Pas d'abonnement mensuel Ã  payer
- **ContrÃ´ler** - Personnalisez et ajustez selon vos besoins

Notre configuration cible :
- ğŸ–¥ï¸ **Mini PC ALTIK** avec Intel i5-10210U (ou similaire)
- ğŸ’¾ **8 Go de RAM** et **SSD 500 Go**
- ğŸ“¦ **Format compact** qui se glisse n'importe oÃ¹
- âš¡ **Consommation modÃ©rÃ©e** (15-35W)

## ğŸ¯ Objectifs du projet

- Installer un systÃ¨me optimisÃ© pour l'IA
- Configurer llama.cpp pour une infÃ©rence efficace
- Installer une interface web conviviale 
- TÃ©lÃ©charger et quantifier des modÃ¨les populaires
- CrÃ©er un systÃ¨me de dÃ©marrage automatique

## ğŸš€ DÃ©marrage rapide

```bash
# Cloner ce dÃ©pÃ´t
git clone https://github.com/creach-t/mini-nuc-llm.git
cd mini-nuc-llm

# Lancer le script d'installation
./install.sh
```

## ğŸ—ï¸ Architecture du projet

```
mini-nuc-llm/
â”œâ”€â”€ install.sh            # Script d'installation principal
â”œâ”€â”€ scripts/              # Scripts utilitaires
â”‚   â”œâ”€â”€ setup_system.sh   # Configuration systÃ¨me
â”‚   â”œâ”€â”€ install_llm.sh    # Installation des modÃ¨les
â”‚   â””â”€â”€ setup_webui.sh    # Configuration interface web
â”œâ”€â”€ models/               # Dossier pour stocker les modÃ¨les
â”œâ”€â”€ webui/                # Interface utilisateur web
â””â”€â”€ docs/                 # Documentation dÃ©taillÃ©e
```

## ğŸ› ï¸ MatÃ©riel recommandÃ©

Notre configuration recommandÃ©e:

| Composant | SpÃ©cification | Notes |
|-----------|---------------|-------|
| Processeur | Intel i5-10210U | 4 cÅ“urs/8 threads, jusqu'Ã  4.2 GHz |
| RAM | 8 Go+ | 16 Go optimal pour modÃ¨les 13B |
| Stockage | SSD 500 Go | NÃ©cessaire pour les modÃ¨les et swap |
| SystÃ¨me | Ubuntu/Debian | Ou Windows avec WSL2 |
| GPU | IntÃ©grÃ© Intel UHD | Suffisant pour les petits modÃ¨les |

## ğŸ“Š Performances attendues

| ModÃ¨le | Taille | Quantification | Temps moyen/token | Notes |
|--------|--------|----------------|-------------------|-------|
| Llama2 | 7B | Q4_K_M | ~50-80 ms | Usage gÃ©nÃ©ral |
| Mistral | 7B | Q4_K_M | ~40-75 ms | Performant |
| Phi-2 | 2.7B | Q4_K_M | ~20-40 ms | Efficace mais limitÃ© |
| TinyLlama | 1.1B | Q4_K_M | ~10-25 ms | TrÃ¨s rapide mais basique |

## ğŸ“‹ Ã‰tapes dÃ©taillÃ©es

### 1ï¸âƒ£ PrÃ©paration du systÃ¨me
Voir [docs/system_setup.md](docs/system_setup.md)

### 2ï¸âƒ£ Installation des dÃ©pendances
Voir [docs/dependencies.md](docs/dependencies.md)

### 3ï¸âƒ£ Installation et compilation de llama.cpp
Voir [docs/llama_cpp.md](docs/llama_cpp.md)

### 4ï¸âƒ£ TÃ©lÃ©chargement et quantification des modÃ¨les
Voir [docs/models.md](docs/models.md)

### 5ï¸âƒ£ Configuration de l'interface utilisateur
Voir [docs/webui.md](docs/webui.md)

### 6ï¸âƒ£ Optimisations avancÃ©es
Voir [docs/optimizations.md](docs/optimizations.md)

## ğŸ“± Interfaces disponibles

- **[llama.cpp server](https://github.com/ggerganov/llama.cpp/tree/master/examples/server)** - API compatible OpenAI
- **[text-generation-webui](https://github.com/oobabooga/text-generation-webui)** - Interface web complÃ¨te
- **[LM Studio](https://lmstudio.ai/)** - Application desktop intuitive
- **Simple terminal** - Via l'exemple main de llama.cpp

## ğŸ’¡ Conseils et astuces

- **Optimisez le swap** pour les modÃ¨les plus gros
- **Ajustez les paramÃ¨tres de contexte** pour Ã©conomiser la RAM
- **Utilisez les modÃ¨les quantifiÃ©s** pour de meilleures performances
- **Essayez diffÃ©rents modÃ¨les** pour trouver le meilleur compromis

## ğŸ”„ Mise Ã  jour

```bash
git pull
./update.sh
```

## ğŸ¤ Contribution

Les contributions sont bienvenues ! Voir [CONTRIBUTING.md](CONTRIBUTING.md) pour les dÃ©tails.

## ğŸ“œ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## â­ Si ce projet vous est utile...

N'hÃ©sitez pas Ã  laisser une Ã©toile sur GitHub et Ã  partager avec ceux qui pourraient Ãªtre intÃ©ressÃ©s !

---

*CrÃ©Ã© avec â¤ï¸ pour rendre l'IA accessible Ã  tous.*